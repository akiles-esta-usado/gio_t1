{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tarea1.algoritmos import hola\n",
    "\n",
    "hola() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# from matplotlib.pyplot import rcParams\n",
    "# %matplotlib inline\n",
    "# rcParams['font.family'] = 'serif'\n",
    "# rcParams['font.size'] = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20:56 empieza a hablar de un ejercicio.\n",
    "\n",
    "Obtener las derivadas para el método de gradiente.\n",
    "Hay que armar el vector gradiente.\n",
    "\n",
    " \n",
    "Sympy: Programación simbólica. Ecuaciones como objetos, puede ser complicado.\n",
    "\n",
    "**Mejor hacer el gradiente a mano.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradiente con Backtracking Line Search 24:50\n",
    "\n",
    "Alpha que es multiplicador de un compadre. Entre 0 y 0.5\n",
    "\n",
    "Beta que actualiza tiempos. Entre 0 y 1 sin tocarlos. \n",
    "\n",
    "¿Tiempos o Steps? Tiempos. Siempre se refiere de esa manera.\n",
    "\n",
    "Hay que crear una igualdad, se evalua. Siempre que se cumpla se actualiza el tiempo.\n",
    "\n",
    "Se parte con el punto inicial 0 0 0\n",
    "\n",
    "---\n",
    "Delta X es - grad F. (26:24 )\n",
    "\n",
    "\n",
    "Mientras no se cumpla la igualdad, se actualizará el punto inicial.\n",
    "P0: (0,0,0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 28:43\n",
    "\n",
    "Hay dos ciclos aniddados\n",
    "\n",
    "1. Busqueda de la condición. La búsqueda del valor de t. T sub optimo para un sub problema\n",
    "2. Con ese t, se actualiza el punto.\n",
    "\n",
    "$$\n",
    "P^{k+1} = P^K +t \\nabla x\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Criterio de parada\n",
    "Hay varias, el ayudante ocupa una en que la norma del vector gradiente sea aproximadamente 0.\n",
    "Osea, menor a un umbral.\n",
    "\n",
    "$$\n",
    "|| \\nabla f(x) || \\approx 0\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akiles\\AppData\\Local\\Temp\\ipykernel_1620\\889348444.py:2: DeprecationWarning: The symbol module is deprecated and will be removed in future versions of Python\n",
      "  from symbol import parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hola\n",
      "0.0010009009786624175 1677\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from symbol import parameters\n",
    "from typing import Any, Callable\n",
    "#from numpy.typing import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class State:\n",
    "  punto: Any\n",
    "  alpha: float\n",
    "  beta: float\n",
    "  f: Callable[..., Any]\n",
    "  fd: Callable[..., Any]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Capture:\n",
    "  k: int\n",
    "  FO_optima: list\n",
    "\n",
    "\n",
    "def state_update(state: State):\n",
    "  punto = state.punto\n",
    "  alpha = state.alpha\n",
    "  beta = state.beta\n",
    "  f = state.f\n",
    "  fd = state.fd\n",
    "\n",
    "  t = 1.0\n",
    "\n",
    "  while True:\n",
    "    LR = f(punto) + alpha * t * np.dot(np.transpose(fd(punto)), - fd(punto))\n",
    "    LL = f(punto - t*fd(punto))\n",
    "    t = t * beta\n",
    "\n",
    "    if LR>LL:\n",
    "      state.punto = punto - t * fd(punto)\n",
    "      break\n",
    "\n",
    "\n",
    "def capture_update(state: State, capture: Capture) -> Capture:\n",
    "\n",
    "  punto = state.punto\n",
    "  f = state.f\n",
    "\n",
    "  capture.k += 1\n",
    "  capture.FO_optima.append(f(punto))\n",
    "\n",
    "  if capture.k % 1000 == 0:\n",
    "    print(\"hola\")\n",
    "\n",
    "\n",
    "def metodo_gradiente(state: State, epsilon=0.001):\n",
    "  \n",
    "  capture = Capture(k=0, FO_optima=list())\n",
    "\n",
    "  f = state.f\n",
    "  fd = state.fd\n",
    "\n",
    "  while True:\n",
    "    state_update(state)\n",
    "\n",
    "    if np.abs(np.linalg.norm(fd(state.punto))) <= epsilon:\n",
    "      break\n",
    "\n",
    "    capture_update(state, capture)\n",
    "\n",
    "\n",
    "  capture_update(state, capture)\n",
    "  print(f(state.punto), capture.k)\n",
    "  \n",
    "  return capture\n",
    "\n",
    "\n",
    "def f(X):\n",
    "  x0 = X[0]\n",
    "  x1 = X[1]\n",
    "  x2 = X[2]\n",
    "  return np.exp( -x0 + 2*x1 ) + np.exp( 3*x2 - 2*x0 ) + x1**2\n",
    "\n",
    "\n",
    "def fd(X):\n",
    "  x0 = X[0]\n",
    "  x1 = X[1]\n",
    "  x2 = X[2]\n",
    "\n",
    "  return np.array([\n",
    "    -np.exp(-x0 + 2*x1) - 2*np.exp( 3*x2 -2*x0 ),\n",
    "    2*np.exp(-x0 + 2*x1) + 2*x1,\n",
    "    3*np.exp(3*x2 - 2*x0)\n",
    "  ])\n",
    "\n",
    "\n",
    "initial_state = State(\n",
    "  np.array([0,0,0]),\n",
    "  alpha=0.3,\n",
    "  beta=0.6,\n",
    "  f=f,\n",
    "  fd=fd\n",
    ")\n",
    "\n",
    "results: Capture = metodo_gradiente(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable Capture object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m alpha \u001b[39m=\u001b[39m \u001b[39m0.3\u001b[39m\n\u001b[0;32m      2\u001b[0m beta \u001b[39m=\u001b[39m \u001b[39m0.6\u001b[39m\n\u001b[1;32m----> 5\u001b[0m FO_optima, k \u001b[39m=\u001b[39m results\n\u001b[0;32m      7\u001b[0m fig, (ax1) \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(nrows\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, figsize\u001b[39m=\u001b[39m(\u001b[39m8\u001b[39m,\u001b[39m5\u001b[39m))\n\u001b[0;32m      9\u001b[0m time\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable Capture object"
     ]
    }
   ],
   "source": [
    "\n",
    "alpha = 0.3\n",
    "beta = 0.6\n",
    "\n",
    "\n",
    "FO_optima, k = results.FO_optima, results.k\n",
    "\n",
    "fig, (ax1) = plt.subplots(nrows=1, figsize=(8,5))\n",
    "\n",
    "time=0\n",
    "label= rf'$\\alpha = {alpha}$, $\\beta = {beta}$, time$= {time}$'\n",
    "\n",
    "ax1.scatter(range(k), FO_optima, s=0.7, label=label)\n",
    "ax1.set_xlabel(\"Número de iteraciones\")\n",
    "ax1.set_ylabel(\"Valor de FO en iteración $k$\")\n",
    "ax1.set_title(\"Convergencia del método\")\n",
    "ax1.legend(loc=\"best\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ILN250_PV_AV_T1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c066d0364de86d471b12b00c49c7831c2a34d591482c833a12f0da5038a80909"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
